# ğŸ“Œ Vida SÄ±nÄ±flandÄ±rma Projesi â€“ Model 1 ve Model 2

Bu repo, iki sÄ±nÄ±flÄ± vida gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma problemi iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r:

* **machine_screw** â†’ makine vidasÄ±  
* **wood_sheet_metal_screw** â†’ ahÅŸap / sac vidasÄ±  

Projede iki farklÄ± model yaklaÅŸÄ±mÄ± denenmiÅŸtir:

* **Model 1 â€“ Transfer Learning (VGG16)**
* **Model 2 â€“ SÄ±fÄ±rdan EÄŸitilen Basit CNN (CIFAR-10 tarzÄ±)**

AÅŸaÄŸÄ±da veri seti, ortam ve her iki model iÃ§in Ã¶zet bilgiler yer almaktadÄ±r.

---

## 1. Veri Seti ve KlasÃ¶r YapÄ±sÄ±

Ham veri Google Drive Ã¼zerinde aÅŸaÄŸÄ±daki yapÄ±dadÄ±r:

```text
project-1/
  dataset/
    machine_screw/             # 63 gÃ¶rÃ¼ntÃ¼
    wood_sheet_metal_screw/    # 63 gÃ¶rÃ¼ntÃ¼
````

Model1 ve Model2 iÃ§in bu veri kontrollÃ¼ ÅŸekilde **train / validation / test** olarak bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r:

```text
project-1/
  dataset_split/
    train/
      machine_screw/           # 40 gÃ¶rÃ¼ntÃ¼
      wood_sheet_metal_screw/  # 40 gÃ¶rÃ¼ntÃ¼
    val/
      machine_screw/           # 10 gÃ¶rÃ¼ntÃ¼
      wood_sheet_metal_screw/  # 10 gÃ¶rÃ¼ntÃ¼
    test/
      machine_screw/           # 13 gÃ¶rÃ¼ntÃ¼
      wood_sheet_metal_screw/  # 13 gÃ¶rÃ¼ntÃ¼
```

* Toplam gÃ¶rÃ¼ntÃ¼: **126**
* Train: **80**
* Validation: **20**
* Test: **26**

EÄŸitim sÄ±rasÄ±nda tÃ¼m gÃ¶rÃ¼ntÃ¼ler:

* `rescale=1./255` ile normalize edilmiÅŸtir,
* `target_size=(128, 128)` ÅŸeklinde yeniden boyutlandÄ±rÄ±lmÄ±ÅŸtÄ±r (hem Model1 hem Model2).

---

## 2. Ortam ve KullanÄ±lan KÃ¼tÃ¼phaneler

* **Google Colab**
* **Python 3**
* **Ana kÃ¼tÃ¼phaneler:**

  * TensorFlow / Keras
  * NumPy
  * Matplotlib

Veriye eriÅŸim iÃ§in Google Drive mount edilmiÅŸtir:

```python
from google.colab import drive
drive.mount('/content/drive')
```

AyrÄ±ca sonuÃ§larÄ±n tekrar edilebilir olmasÄ± iÃ§in seed ayarÄ± yapÄ±lmÄ±ÅŸtÄ±r:

```python
import numpy as np, tensorflow as tf, random

SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
random.seed(SEED)
```

---

## 3. Model 1 â€“ Transfer Learning ile VGG16 (`Model1.ipynb`)

### 3.1. Temel VGG16 TabanÄ±

* `VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))`
* Son sÄ±nÄ±flandÄ±rma bloÄŸu kaldÄ±rÄ±lmÄ±ÅŸtÄ±r.
* BaÅŸlangÄ±Ã§ aÅŸamasÄ±nda:

```python
base_model.trainable = False
```

---

### 3.2. Ä°lk Model1 Denemesi â€“ GAP + Dense

Model mimarisi:

* VGG16 (dondurulmuÅŸ)
* `GlobalAveragePooling2D`
* `Dense(128, activation='relu')`
* `Dropout(0.5)`
* `Dense(2, activation='softmax')`

**EÄŸitim AyarlarÄ±:**

* `Adam(1e-4)`
* `categorical_crossentropy`
* `accuracy` metriÄŸi
* `EPOCHS = 30`
* `EarlyStopping(patience=3)`

**SonuÃ§ (Ã¶zet):**

* Train accuracy â‰ˆ **0.90**
* Validation accuracy â‰ˆ **0.70â€“0.75**
* Test accuracy â‰ˆ **0.50**

Bu nedenle geliÅŸtirme ihtiyacÄ± gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.

---

### 3.3. Ä°yileÅŸtirilmiÅŸ Model 1 â€“ Daha Derin Dense Blok (Final)

PerformansÄ± artÄ±rmak iÃ§in Ã¼st sÄ±nÄ±flandÄ±rma bloÄŸu yeniden tasarlanmÄ±ÅŸtÄ±r.

**Final Model MimarÄ±si (Flatten + Dense):**

* VGG16 (dondurulmuÅŸ)
* `Flatten()`
* `Dense(256, activation='relu')`
* `Dropout(0.3)`
* `Dense(128, activation='relu')`
* `Dropout(0.3)`
* `Dense(2, activation='softmax')`

**EÄŸitim AyarlarÄ±:**

* `Adam(1e-4)`
* `categorical_crossentropy`
* `accuracy`
* `EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)`
* En fazla 30 epoch (erken durdurma aktif)

**Performans (Ã¶zet):**

* Train accuracy â‰ˆ **0.90**
* Validation accuracy â‰ˆ **0.80**
* Test accuracy â‰ˆ **0.61**

> Not: Test seti yalnÄ±zca 26 Ã¶rnek iÃ§erdiÄŸi iÃ§in, tek bir gÃ¶rÃ¼ntÃ¼nÃ¼n doÄŸru/yanlÄ±ÅŸ sÄ±nÄ±flanmasÄ± accuracyâ€™yi yaklaÅŸÄ±k %3â€“4 oranÄ±nda deÄŸiÅŸtirebilmektedir.

---

### 3.4. Fine-Tuning Denemesi â€“ VGG16 Block 5

Ek deney olarak fine-tuning uygulanmÄ±ÅŸtÄ±r:

* `block5_*` katmanlarÄ± `trainable = True` yapÄ±lmÄ±ÅŸtÄ±r.
* DiÄŸer katmanlar donuk bÄ±rakÄ±lmÄ±ÅŸtÄ±r.
* Ã–ÄŸrenme oranÄ± dÃ¼ÅŸÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r:

```python
Adam(1e-5)
```

* `EarlyStopping` ile kÄ±sa ek eÄŸitim yapÄ±lmÄ±ÅŸtÄ±r.

**SonuÃ§:**

* Validation accuracy yine â‰ˆ **0.80**
* Test accuracy yine â‰ˆ **0.61**

Bu nedenle Fine-Tuning, test performansÄ±nÄ± anlamlÄ± biÃ§imde artÄ±rmadÄ±ÄŸÄ± iÃ§in final modele dahil edilmemiÅŸ; raporda â€œek deneyâ€ olarak bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

---

## 4. Model 2 â€“ SÄ±fÄ±rdan EÄŸitilen Basit CNN (`model2.ipynb`)

Model 2â€™de amaÃ§, **transfer learning kullanmadan**, CIFAR-10 benzeri **basit bir CNN mimarisini sÄ±fÄ±rdan** eÄŸitip aynÄ± veri seti Ã¼zerinde performansÄ± gÃ¶zlemlemektir. BÃ¶ylece Model 1 ve Model 2 sonuÃ§larÄ± doÄŸrudan karÅŸÄ±laÅŸtÄ±rÄ±labilir.

### 4.1. Veri ve Girdi AyarlarÄ±

Model 2 de aynÄ± `dataset_split` yapÄ±sÄ±nÄ± kullanÄ±r:

* Train: 80 gÃ¶rÃ¼ntÃ¼ (40 + 40)
* Validation: 20 gÃ¶rÃ¼ntÃ¼ (10 + 10)
* Test: 26 gÃ¶rÃ¼ntÃ¼ (13 + 13)

TÃ¼m gÃ¶rÃ¼ntÃ¼ler:

```python
ImageDataGenerator(rescale=1./255)
target_size = (128, 128)
batch_size = 8  # veya 16
class_mode = 'categorical'
```

ÅŸeklinde Keras `flow_from_directory` ile okunmuÅŸtur. Train/val/test iÃ§in ayrÄ± generatorâ€™lar tanÄ±mlanmÄ±ÅŸtÄ±r.

---

### 4.2. Model 2 CNN Mimarisi

Model 2, Ã¼Ã§ konvolÃ¼syon bloÄŸu ve ardÄ±ndan basit bir tam baÄŸlÄ± kÄ±sÄ±mdan oluÅŸan klasik bir CNNâ€™dir.

```python
model2 = Sequential([
    # GiriÅŸ
    Input(shape=(128, 128, 3)),

    # Blok 1
    Conv2D(32, (3, 3), padding='same', activation='relu'),
    MaxPooling2D((2, 2)),

    # Blok 2
    Conv2D(64, (3, 3), padding='same', activation='relu'),
    MaxPooling2D((2, 2)),

    # Blok 3
    Conv2D(128, (3, 3), padding='same', activation='relu'),
    MaxPooling2D((2, 2)),

    # Tam baÄŸlÄ± kÄ±sÄ±m
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.3),
    Dense(2, activation='softmax')
])
```

Bu yapÄ±, CIFAR-10 Ã¶rneklerinde kullanÄ±lan basit CNNâ€™lere benzer olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r; herhangi bir Ã¶n-eÄŸitim (pretrained weights) kullanÄ±lmamÄ±ÅŸtÄ±r.

---

### 4.3. EÄŸitim AyarlarÄ±

Model 2 iÃ§in kullanÄ±lan temel eÄŸitim ayarlarÄ±:

```python
model2.compile(
    optimizer=Adam(learning_rate=2e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

early_stop2 = EarlyStopping(
    monitor='val_accuracy',
    patience=8,
    restore_best_weights=True
)

EPOCHS = 50  # early stopping ile genelde daha erken duruyor
```

EÄŸitim sÄ±rasÄ±nda:

* EÄŸitim ve doÄŸrulama doÄŸruluk/kayÄ±p deÄŸerleri kayÄ±t altÄ±na alÄ±nmÄ±ÅŸ,
* `Model 2 - EÄŸitim ve DoÄŸrulama DoÄŸruluÄŸu` ve
  `Model 2 - EÄŸitim ve DoÄŸrulama KayÄ±p DeÄŸerleri` grafikleri Ã§izdirilmiÅŸtir.

---

### 4.4. Model 2 SonuÃ§larÄ± (Ã–zet)

SeÃ§ilen final konfigÃ¼rasyon iÃ§in gÃ¶zlenen tipik deÄŸerler:

* **En yÃ¼ksek validation accuracy** â‰ˆ **0.65â€“0.70**
* EÄŸitim doÄŸruluÄŸu epoch sonlarÄ±nda â‰ˆ **0.70** seviyesine yaklaÅŸmaktadÄ±r.
* **Test accuracy** â‰ˆ **0.42**
  (26 Ã¶rnek iÃ§in bu, yaklaÅŸÄ±k 11/26 doÄŸru sÄ±nÄ±flama anlamÄ±na gelir.)

Loss grafikleri incelendiÄŸinde:

* Hem train loss hem val loss zamanla azalmakta,
* AralarÄ±ndaki fark Ã§ok aÃ§Ä±lmadÄ±ÄŸÄ± iÃ§in aÅŸÄ±rÄ± overfitting gÃ¶zlenmemektedir,
* Ancak kÃ¼Ã§Ã¼k veri seti ve sÄ±fÄ±rdan eÄŸitim nedeniyle modelin genelleme kapasitesi sÄ±nÄ±rlÄ± kalmaktadÄ±r.

Bu sonuÃ§lar, sÄ±fÄ±rdan eÄŸitilen basit CNNâ€™in bu veri setinde **orta dÃ¼zey bir performans** saÄŸladÄ±ÄŸÄ±nÄ±, ancak transfer learningâ€™e gÃ¶re daha zayÄ±f kaldÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

---

## 5. Model 1 ve Model 2 KarÅŸÄ±laÅŸtÄ±rmasÄ±

AynÄ± veri bÃ¶lÃ¼nmesi Ã¼zerinde iki modelin test performanslarÄ± kabaca ÅŸÃ¶yledir:

* **Model 1 (VGG16, transfer learning)**

  * Test accuracy â‰ˆ **0.61**
* **Model 2 (basit CNN, sÄ±fÄ±rdan eÄŸitim)**

  * Test accuracy â‰ˆ **0.42**

Bu farkÄ±n baÅŸlÄ±ca nedenleri:

1. **Ã–nceden EÄŸitilmiÅŸ Ã–zellikler:**
   VGG16, ImageNet Ã¼zerinde eÄŸitildiÄŸi iÃ§in kenar, doku, ÅŸekil gibi dÃ¼ÅŸÃ¼k/orta seviye gÃ¶rsel Ã¶zellikleri zaten iyi Ã¶ÄŸrenmiÅŸ durumdadÄ±r. KÃ¼Ã§Ã¼k vida veri seti Ã¼zerinde sadece Ã¼st sÄ±nÄ±flandÄ±rÄ±cÄ± katmanlarÄ±n eÄŸitilmesi bile yÃ¼ksek performans saÄŸlamaktadÄ±r.

2. **Veri MiktarÄ± ve SÄ±fÄ±rdan EÄŸitim:**
   Model 2â€™de tÃ¼m aÄŸÄ±rlÄ±klar sÄ±fÄ±rdan rastgele baÅŸlatÄ±lmÄ±ÅŸtÄ±r. Her sÄ±nÄ±f iÃ§in yalnÄ±zca 40 eÄŸitim gÃ¶rÃ¼ntÃ¼sÃ¼ (toplam 80 Ã¶rnek) ile bu aÄŸÄ±n hem dÃ¼ÅŸÃ¼k seviyeli hem yÃ¼ksek seviyeli Ã¶zellikleri aynÄ± anda Ã¶ÄŸrenmesi zordur. Bu nedenle test setinde genelleme performansÄ± sÄ±nÄ±rlÄ± kalmaktadÄ±r.

SonuÃ§ olarak:

> KÃ¼Ã§Ã¼k ve sÄ±nÄ±rlÄ± bir veri setinde, **transfer learning (Model 1)** yaklaÅŸÄ±mÄ±, **sÄ±fÄ±rdan eÄŸitilen basit CNN (Model 2)** yaklaÅŸÄ±mÄ±na gÃ¶re daha yÃ¼ksek ve daha kararlÄ± bir performans sunmuÅŸtur.

---

## 6. Ã‡alÄ±ÅŸtÄ±rma AdÄ±mlarÄ± (KÄ±sa Ã–zet)

1. **Drive baÄŸlantÄ±sÄ±**

   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

2. **Veri hazÄ±rlama**

   * Ham veri: `dataset/`
   * Train/Val/Test: `dataset_split/` iÃ§inde

     * Train: 80, Val: 20, Test: 26 Ã¶rnek.

3. **Model 1 (VGG16 â€“ Transfer Learning) â€“ `Model1.ipynb`**

   * VGG16 tabanÄ±nÄ± yÃ¼kle (`include_top=False`, `weights='imagenet'`).
   * Ãœst sÄ±nÄ±flandÄ±rÄ±cÄ± bloÄŸu (Flatten + Dense(256,128) + Dropout) ekle.
   * `Adam(1e-4)` ile eÄŸit, EarlyStopping uygula.
   * EÄŸitim/val grafiklerini Ã§iz ve test doÄŸruluÄŸunu raporla.

4. **Model 2 (Basit CNN) â€“ `model2.ipynb`**

   * AynÄ± `dataset_split` klasÃ¶rÃ¼nÃ¼ kullan.
   * 3 konvolÃ¼syon bloÄŸu + Flatten + Dense(256) + Dropout + Dense(2) mimarisi kur.
   * `Adam(2e-4)` ile eÄŸit, EarlyStopping uygula.
   * EÄŸitim/val grafiklerini Ã§iz ve test doÄŸruluÄŸunu raporla.

5. **KarÅŸÄ±laÅŸtÄ±rma**

   * Model1 ve Model2â€™nin validation/test doÄŸruluklarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r.
   * Transfer learningâ€™in kÃ¼Ã§Ã¼k veri setlerinde saÄŸladÄ±ÄŸÄ± avantajÄ± tartÄ±ÅŸ.

